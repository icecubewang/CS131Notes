# W6;L1

## Threads in Java üßµ 

- Created with `new` (i.e `Thread t = new Thread()`)
- `t.start()` - tell the OS to create/allocate thread which will execute `t.run()`
- while running a thread can:
  - do normal thread stuff
  - exit the `run` method
    - transitions to `TERMINATED` thread state
  - sleep
  - wait
  - do I/O
- multiple possible states:
  - `NEW`
  - `TERMINATED`
  - `RUNNING`
  - `RUNNABLE`
  - `TIMEDWAITING`
  - `WAITING`
  - `BLOCKED`
- upon `exit` or termination, garbage collection üóë:truck:

## Synchronization üîÑ in Java

Uses the `synchronized` keyword that locks other threads out from accessing their object

- locks the OBJECT not the class overall obviously lol
- implemented with spin locks under the hood (not very performant)

```java
public class C {
    int ctr;
    public synchronized int incr() {
        ctr++;
    }
}
```



|         T1          |             T2              |
| :-----------------: | :-------------------------: |
|      o.incr()       |          o.incr()           |
| accepted; owns lock | rejected; does not own lock |

If we have:

```java
public class C {
    int ctr;
    public synchronized int incr() {
        ctr++;
    }
    public synchronized int decr() {
        ctr--;
    }
}
```

- Then when T1 calls `incr()` it will also lock it from T2 calling `decr()`
- All synchronized methods share the same lock basically then

### High Performance ‚ö°Ô∏è 

The above works sure but it kinda sucks for high performance situations.

So, the Java engineers üõ† made new options:

- `o.wait()`
  - gives up the CPU to allow other threads to do work UNTIL some other thread calls `notify`
- `o.notify()`
  - wake up one waiting thread
- `o.notifyAll()`
  - wake up all waiting threads (on this specific lock ofc)

## Semaphores and Friends

### Semaphores

- All the traditional methods:
  - `s.tryAcquire()`
  - `s.acquire()`
  - `s.release()`

### Exchangers üñê 

- `x.exchange(vout)`
- Like a spy trying to exchange a secret for money with the "spy master"
- Allows two threads to exchange objects without worrying about race conditions
- Once it returns in EITHER thread, you know that BOTH threads have been satisfied 
- Use case:
  - You have partitioned your program into two pieces (spy and spy master), most of which can be done independently, but with the occasional need for exchanging data

### Count Down Latch üîíüîíüîí 

- Like exchanger but uses multiple pieces
- Picture a number of slots, one for each thread that can rendezvous 
- Think of a horse race: they're milling around the track and eventually they all get into the countdown latch you can arrange to have code execute while you know you have all the horses and then say "they're off!" and let them start running
- This lets you do some preparation for global variables and stuff at the cost of eliminating parallelism
- A common approach for scientific programming is to break down one problem into multiple pieces and work on each one, but needing coordination sometimes
  - ex: weather simulation: divide a map of the US into a grid, assign each block in the grid to a separate thread
  - each thread can simulate what happens to temperate, air mass, wind, etc.
  - however, the temperatures at the edges of one block will affect the temperatures at the edges of other blocks
  - count down locks are good, but they only work once! ‚òùÔ∏è 
  - we need to have a whole new set of count down latches for every single iteration üò¨
  - thus bringing up:

### Cyclic Barriers üå™ 

- like a horse race but every time the horses finish one lap they wait for all the others. to get back
- this way the threads/horses can exchange information every "iteration"

### A Contender üëÄ 

What if the way we are designing programs is wrong? Synchronization introduces bugs and makes your program slower. Instead you should write your code **without** synchronization and multi-thread it

Of course your code will have bugs, but design your program so the bugs don't matter as much

- ex: weather simulation, just run it without all the synchronization methods and accept the fact that it will be somewhat inaccurate ü§∑‚Äç‚ôÇÔ∏è 
- ex: machine learning. machine learning needs a lot of CPU cycles with a lot of "bogus/magic" numbers and data anyways, so some ML people have just decided to run unsynchronized
  - that's what project 3 is about! we are a python hacker that knows nothing about synchronization and just wants the best data the fastest üèÉ 
  - used when performance matters so much you are willing to give up some correctness to get there ü§∑‚Äç‚ôÇÔ∏è 

## Java Memory Model ‚òïÔ∏è üß†

Imagine that we are living inside a two-dimensional world: there is the x-axis tha. tells you where you are in space and the t-axis that tells you where you are in time

- the speed of light is 1 in this universe (`c=1`)
- if you take a beam of light and shine in on the x-axis, then the beam of light will travel linearly (`x=y`)
- if you are in a car, it will go much slower
- this grid represents the space in our universe that we can send messages to (i.e. picture someone shooting a bullet at you, as time moves on (the t-axis gets less negative), then the bullet gets closer (the x-axis gets closer to 0 (closer to you)))
- the analogy here is sending a message

Wtf does this have to do with the Java memory model?

### Causality ü¶ã ‚è∞ üí• 

*What can one thread do that affects another thread? How does one thread communicate with another?*



Most programmers are not explained the JMM. They are told "use synchronized." If that doesn't work, hire somebody who knows what they're doing.

**IF YOU ARE READING THIS, THEN YOU ARE THE PERSON WHO IS SUPPOSED TO KNOW WHAT THEY'RE DOING**

EXCEPT! ‚òùÔ∏è 

the spec is not written for you! the spec is written at Oracle for Java language engineers

Therefore, we must explain the JMM in terms that WE understand

### Explained

#### "as-if" rule

The language standards specifies the desired *behavior* of the language, but does *NOT specify implementation*

- it specifies a MODEL
- "integers contain 32 bits, it's twos-complements, you can. load from an integer, etc."
- this is the "**model of computation**"
  - the implementation must follow this model
  - but it can do it anyway it wants to
  - i.e. the implementation can depart from the model iff ‚òùÔ∏è the programmer cannot tell the difference ü§∑‚Äç‚ôÇÔ∏è 

ex: you have a function that creates 64 boolean variables, but when you look at the machine code, you notice that the compiler did not allocate 64 separate boolean variables

- what happened is the compiler decided to use the `rdx` register and use one bit per boolean
- but since you cannot tell the difference, this implementation is ok

#### Delicate Data Structure üêç :five: :on: :six:

```java
class Delicate {
    boolean outofservice;
    int i, j, k;
    
    int update(void) {
        outofservice = true;
        j = 1;
        k++;
        i = j + k;
        outofservice = false;
    }
    
    int access() {
        while (outofservice) {
            
        }
        return i + j + k;
    }
}
```

the reason we do this instead of the `synchronized` method is that it's SLOW üê¢ and it causes bottlenecks

is this approach good?

- NO
- because the compiler can reorder the accesses inside `update()`, even just set `outofservice` to false because of optimizations
- so we have the "as-if" rule that wants performance and we have the desire to make this implementation work, and the two are warring ü•ä against each other

#### volatile

This tells the compiler "you can't play these games anymore" ‚ôü 

and the compiler will not reorder the accesses

