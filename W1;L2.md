# W1;L2

Languages/notations have *niches*. They do not start out trying to take over the world and become everybody's favorite.

- Latex - text document formatting/typesetting
- R - stats 
- Mathematica, MATLAB - math
- OpenCL - parallel processing

The above are referred to as **domain-specific languages.** They do not aim to be general purpose, but are so popular they become almost inherent to their field.

Some, however, are more ambitious.

- JavaScript - originally intended for browser-scripting, now everywhere
- C - originally intended for text processing and operating systems, now very common place (particularly C++)

## Language Evolution :monkey: :man:

Successful and persistent languages evolve.

BASIC originally only supported 40KiB of RAM and supported 20-30 users (one of them was Eggert lol) at a time. Because it was interpreted, you could only have several variables declared and needed comments to provide documentation.

```
					Simula67 \
							  C++
Fortan => PL/1 => BCPL => C  /
```

Languages can become opinionated due to historical environments and constraints. For example, C was developed on a PDP11 machine, in which memory cycle times were much faster than arithmetic/CPU time. Due to this, C encourages dereferencing pointers (`*p`) and CPU-intensive operations are harder.



### Sidenote:

> It now takes about 1 nanosecond to add two numbers and 100 ns to talk to RAM. Because talking to RAM is 100 times slower than doing a computation, C is declining in popularity.



Rather than creating a whole new language, you can evolve *within* a language. For example, C++ technology being used in C. 

- `close(fd)`
- You say `close(5)`. But 5 is not open! On every machine NOT made by Microsoft, it will say error! :no_entry: return -1. 
- However, on Microsoft, it will throw an exception. 
- C doesn't have exceptions!
  - You should be using C# :))))))))) made by Microsoft :))))
- Therefore, you do something like this:

```c
int rpl_close (int fd) {
    TRY:
    	n = close(fd);
    CATCH:
    	n = 1; errno = EBAD;
    DONE:
    	return n;
}

// and now define the macros TRY, CATCH, and DONE to resolve to curly brackets {}

// and:
#define close rpl_close (replacement close)
```

The above convoluted procedure is a reasonable enough thing to do **in languages that evolve** without needing a new language or compiler.

However, one should be careful not to take it too far!

Example: Steve Bourne (inventor of the shell) came from the ALGOL language and was used to the following syntax/style:

```
IF a==b
THEN 	a=1,
		b=2
ELSE 	c=3,
		d=4
FI

#define IF if (
#define THEN ){
#define ELSE } else {
#define FI }
```

Why is this too far?

Because everyone hated it! ðŸ¤® And it was eventually killed off when GNU released BASH.

## Homework 1

We'll be using a language that has gone through all of these processes. It has evolved. It is contentious and controversial.

Lisp.

### *STORYTIME*

It's 2002. There's a company called Google. They have too much data to process efficiently. Engineers struggle to write programs fast enough to answer the questions demanded. Big-ish data.

The engineers write a bunch of C++ code. When you write too much C++ code, you will eventually get something that runs, but is unreliable and hard to debug. It is hard to maintain. We have a bunch of ad hoc queries. And to reliably process this biggish data, we need to run on networked computers. A big network where you don't even know where these computers are half the time.

The Google engineers did what any good programmer would do: look at their neighbor and copy them.

ENTER: MapReduce

You have a big problem, too big to solve on any one computer. So, you break down said problem into independently solvable problems N times and then solve the big problem N times faster! This is the "Map" part. You then combine these solutions in the "Reduce" part.

Too bad they stole the idea from Lisp, which has  `map` and `reduce` functions.

In this programming style, you never have any assignment statements or change variable values. A very different style of programming which is, of course, **functional programming.**

*/STORYTIME*

### Programming paradigms:

- Imperative - about **command**; assignment and iteration: you give the computer a recipe and the computer follows the recipe, step by step in the order you specified.
  - C, C++, Java
  - Command1; Command2; ... ; CommandN
  - Thrives on *sequence*, following a certain order of execution which derives from how machine code is executed.
- Functional - about **functions**; recursion and single line values
  - Lisp, Scala, ML, F#, OCaml
  - function1 (function2 (function3 (... (functionN(x)))))
  - You don't have commands, you have *functions* in which there are NO side effects, no assignments
- Logical - about **predicates**: statements about the world that are either TRUE or FALSE
  - Prolog
  - (P1 & P2) ... (| PN)
  - No function calls; connected through boolean operations

## Functional Languages :hammer_and_wrench:

You are not merely "giving up" control or command by avoiding side-effects. You legitimately gain an advantage.

### Side Effects

> When a function is called not PURELY because of their return values but due to some other functionality, the function is said to have **side effects**. Impure functions depend on program state and thus require previous knowledge of the program to understand.
>
> sin function is side-effect free.
>
> putchar is not.

### Motivation

1. Clarity - programs in C can be - no surprise - hard to read and understand; they can be confusing
   1. Mathematicians have centuries of notational experience to make things easy to understand and the designers of Fortran and C threw this all away!!! They even misused some of the notation (ex: `n=n+1`)
   2. Remedy: Let's USE this valuable experience and knowledge mathematicians have accumulated.
2. Parallelizability/Efficiency :white_check_mark: 
   1. We want to escape from the von Neumann bottleneck which is inherent to the kinds of machines we traditionally think about
      1. You have a CPU connected to the RAM by buses and you have IO and ultimately the amount of computation you can do is limited by the bus between the CPU and RAM. This is called the bottleneck.
   2. To escape this bottleneck, you have to **maximize parallelizability**. To do this, you need to get rid of the idea of *sequence*, which is fundamental to imperative languages (you execute command1 before command2).
      1. Even with out of order execution found on modern machines, you cannot achieve the same amount of speed-up because even with out of order exec you have to stay reasonably within order.
   3. You can also (largely) **eliminate race conditions**.

### History

J Backus looked at Fortran's success and said the biggest problem with Fortan and C were their *side-effects*. If we want to have **high quality software that runs fast**, they are headed down the WRONG direction.

### Functions

*Function* - A mapping from a domain to a range; a set of ordered pairs (domain range) where no two domains have the same range.

*Functional form* - A more abstract concept of a function; a higher-order function in the sense that it takes arguments that can also be functions. (JavaScript for the win!!!) 

- Function composition `h = f(g) ==> h(x) = f(g(x))`
- Ex: integrals: a functional form with three arguments: a lower bound, upper bound, and function.

$$
\int_{0}^{h} f(x)dx
$$

Where you give the integral a function `f(x)` and it returns a real value.

### Order of Evaluation :1234:

Not determined by semi-colons lol

Determined by function calls and recursion.

If you want to execute something in order, you should arrange the program such that the argument to a function must be evaluated before the function itself is executed.

By doing this, **dependencies become clearer** because you are not relying on side-effects.

Since there are no variables in the C/Fortran sense, there is no longer a level of indirection between variables and values.

- In a C program, a variable can have a value of 3 at one point and 27 at another. i.e. `v = 3; ... v = 27;`
- In a functional program, a variable must always have the same value. i.e. `v` will **always** be the same value.
  - The fancy term for this is **referential transparency**, or it is always **immediately obvious** what the value of a variable is, no matter where you are in the code.
  - This makes the code much simpler to follow and understand, theoretically.
- Furthermore, when compilers translate your code, they can perform many more optimizations. 
  - i.e. in imperative languages, the compiler will always have to have a `load` instruction for every single variable every time it is reference because it cannot guarantee that the variable has not changed.
  - in functional languages, the compiler can assume that the value of a variable is constant and thus must **only load once**.

